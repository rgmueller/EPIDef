{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def get_list_ids(lf_directory):\n",
    "    \"\"\"\n",
    "\n",
    "    :param lf_directory:\n",
    "    :return: list_ids:\n",
    "    \"\"\"\n",
    "    good = 0\n",
    "    scratch = 0\n",
    "    dent = 0\n",
    "    error = 0\n",
    "    list_ids = []\n",
    "    for path, subdirs, files in os.walk(lf_directory):\n",
    "        if '0001_Set0_Cam_003_img.png' in files:  # only add paths with images\n",
    "            list_ids.append(path)\n",
    "            if 'good' in path:\n",
    "                good += 1\n",
    "            elif 'scratch' in path:\n",
    "                scratch += 1\n",
    "            elif 'dent' in path:\n",
    "                dent += 1\n",
    "            else:\n",
    "                error += 1\n",
    "    random.seed(1)\n",
    "    random.shuffle(list_ids)\n",
    "    print(f\"Good: {good/(good+scratch+dent+error)}\")\n",
    "    print(f\"Scratch: {scratch / (good + scratch + dent + error)}\")\n",
    "    print(f\"Dent: {dent / (good + scratch + dent + error)}\")\n",
    "    print(f\"Error: {error / (good + scratch + dent + error)}\")\n",
    "    return list_ids\n",
    "\n",
    "\n",
    "def load_lightfield_data(list_ids, img_size):\n",
    "    \"\"\"\n",
    "    Loads lightfield images from directory.\n",
    "    Images are loaded in following pattern:\n",
    "             12\n",
    "             11\n",
    "             10\n",
    "    06 05 04 03 02 01 00\n",
    "             09\n",
    "             08\n",
    "             07\n",
    "\n",
    "    :param img_size:\n",
    "    :param list_ids: Paths to directories\n",
    "    :return: features: (#LF, resX, resY, hor_or_vert, #img, RGB)\n",
    "             labels: (#LF)\n",
    "    \"\"\"\n",
    "    # print(\"\\nNow training on:\")\n",
    "    features = np.zeros((len(list_ids), img_size, img_size, 14), np.float32)\n",
    "    labels = np.zeros((len(list_ids)), np.int64)\n",
    "    for i, lf in enumerate(list_ids):\n",
    "        # print(lf.split('\\\\')[-2:])\n",
    "\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 0] = (0.299*im_resize[:, :, 0] + 0.587*im_resize[:, :, 1]\n",
    "                                    + 0.114*im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 1] = (0.299*im_resize[:, :, 0] + 0.587*im_resize[:, :, 1]\n",
    "                                    + 0.114*im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 2] = (0.299*im_resize[:, :, 0] + 0.587*im_resize[:, :, 1]\n",
    "                                    + 0.114*im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 3] = (0.299 * im_resize[:, :, 0] + 0.587 * im_resize[:, :, 1]\n",
    "                                + 0.114 * im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 4] = (0.299 * im_resize[:, :, 0] + 0.587 * im_resize[:, :, 1]\n",
    "                                + 0.114 * im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 5] = (0.299 * im_resize[:, :, 0] + 0.587 * im_resize[:, :, 1]\n",
    "                                + 0.114 * im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 6] = (0.299 * im_resize[:, :, 0] + 0.587 * im_resize[:, :, 1]\n",
    "                                + 0.114 * im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 7] = (0.299 * im_resize[:, :, 0] + 0.587 * im_resize[:, :, 1]\n",
    "                                + 0.114 * im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 8] = (0.299 * im_resize[:, :, 0] + 0.587 * im_resize[:, :, 1]\n",
    "                                + 0.114 * im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 9] = (0.299 * im_resize[:, :, 0] + 0.587 * im_resize[:, :, 1]\n",
    "                                + 0.114 * im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 10] = (0.299 * im_resize[:, :, 0] + 0.587 * im_resize[:, :, 1]\n",
    "                                 + 0.114 * im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 11] = (0.299 * im_resize[:, :, 0] + 0.587 * im_resize[:, :, 1]\n",
    "                                 + 0.114 * im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 12] = (0.299 * im_resize[:, :, 0] + 0.587 * im_resize[:, :, 1]\n",
    "                                 + 0.114 * im_resize[:, :, 2])\n",
    "        with Image.open(f\"{lf}\\\\0001_Set0_Cam_003_img.png\") as im:\n",
    "            im_resize = np.array(im.resize((img_size, img_size))).astype('float32')\n",
    "        features[i, :, :, 13] = (0.299 * im_resize[:, :, 0] + 0.587 * im_resize[:, :, 1]\n",
    "                                 + 0.114 * im_resize[:, :, 2])\n",
    "\n",
    "        # 0: no defect, 1: scratch, 2: dent\n",
    "        if 'good' in lf:\n",
    "            gt = 0\n",
    "        elif 'scratch' in lf:\n",
    "            gt = 1\n",
    "        elif 'dent' in lf:\n",
    "            gt = 2\n",
    "        else:\n",
    "            gt = 'error'\n",
    "        labels[i] = gt\n",
    "    return features/255, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "import tensorflow as tf\n",
    "from official.vision.image_classification.efficientnet import efficientnet_model\n",
    "\n",
    "\n",
    "def efficientnet():\n",
    "    \"\"\"\n",
    "    Merged layer: Conv - ReLU - Conv - ReLU - BN\n",
    "\n",
    "    :return: seq:\n",
    "    \"\"\"\n",
    "    block_config = efficientnet_model.BlockConfig()\n",
    "\n",
    "#     blocks = (  # (input_filters, output_filters, kernel_size, num_repeat,\n",
    "#         #  expand_ratio, strides, se_ratio)\n",
    "#         block_config.from_args(32, 16, 3, 1, 1, (1, 1), 0.25),\n",
    "#         block_config.from_args(16, 24, 3, 2, 6, (2, 2), 0.25),\n",
    "#         block_config.from_args(24, 40, 5, 2, 6, (2, 2), 0.25),\n",
    "#         block_config.from_args(40, 80, 3, 3, 6, (2, 2), 0.25),\n",
    "#         block_config.from_args(80, 112, 5, 3, 6, (1, 1), 0.25),\n",
    "#         block_config.from_args(112, 192, 5, 4, 6, (2, 2), 0.25),\n",
    "#         block_config.from_args(192, 320, 3, 1, 6, (1, 1), 0.25),\n",
    "#     )\n",
    "    seq = efficientnet_model.EfficientNet(overrides={'num_classes': 3,\n",
    "                                                     'input_channels': 14,\n",
    "                                                     'rescale_input': False,\n",
    "#                                                      'blocks': blocks,\n",
    "#                                                      'stem_base_filters': 32\n",
    "                                                    })\n",
    "    return seq\n",
    "\n",
    "\n",
    "def define_epidef(sz_input1, sz_input2):\n",
    "    \"\"\"\n",
    "    Compiles the full network.\n",
    "\n",
    "    :param sz_input1: resX\n",
    "    :param sz_input2: resY\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    # 2-Input: Conv - ReLU - Conv - ReLU - BN\n",
    "    input_ = Input(shape=(sz_input1, sz_input2, 14), name='input_stack_vert')\n",
    "\n",
    "    # Merge layers\n",
    "    mid_merged_ = efficientnet()\n",
    "\n",
    "    output = mid_merged_(input_)\n",
    "    model_512 = Model(inputs=input_, outputs=[output])\n",
    "    metrics = ['accuracy',\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall')]\n",
    "    model_512.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)\n",
    "    model_512.summary()\n",
    "    return model_512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lightfield paths...\n",
      "Good: 0.5599393019726859\n",
      "Scratch: 0.2028325746079919\n",
      "Dent: 0.2372281234193222\n",
      "Error: 0.0\n",
      "Done loading lightfield paths.\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_stack_vert (InputLayer [(None, 224, 224, 14)]    0         \n",
      "_________________________________________________________________\n",
      "efficientnet (EfficientNet)  (None, 3)                 4056575   \n",
      "=================================================================\n",
      "Total params: 4,056,575\n",
      "Trainable params: 4,014,559\n",
      "Non-trainable params: 42,016\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1383/1383 - 42s - loss: 1.6341 - accuracy: 0.4389 - precision: 0.4535 - recall: 0.3984 - val_loss: 9.1557 - val_accuracy: 0.3805 - val_precision: 0.3782 - val_recall: 0.3737\n",
      "Epoch 2/100\n",
      "1383/1383 - 42s - loss: 1.4302 - accuracy: 0.4584 - precision: 0.4954 - recall: 0.3919 - val_loss: 2.7056 - val_accuracy: 0.3973 - val_precision: 0.3979 - val_recall: 0.3805\n",
      "Epoch 3/100\n",
      "1383/1383 - 41s - loss: 1.2591 - accuracy: 0.4873 - precision: 0.5229 - recall: 0.3962 - val_loss: 1.4274 - val_accuracy: 0.3906 - val_precision: 0.4089 - val_recall: 0.2795\n",
      "Epoch 4/100\n",
      "1383/1383 - 42s - loss: 1.2369 - accuracy: 0.5033 - precision: 0.5366 - recall: 0.3868 - val_loss: 1.2929 - val_accuracy: 0.5017 - val_precision: 0.5041 - val_recall: 0.4175\n",
      "Epoch 5/100\n",
      "1383/1383 - 42s - loss: 1.1975 - accuracy: 0.5061 - precision: 0.5596 - recall: 0.3803 - val_loss: 3.1326 - val_accuracy: 0.3350 - val_precision: 0.3333 - val_recall: 0.3283\n",
      "Epoch 6/100\n",
      "1383/1383 - 43s - loss: 1.1871 - accuracy: 0.5148 - precision: 0.5354 - recall: 0.3832 - val_loss: 1.1763 - val_accuracy: 0.5421 - val_precision: 0.5432 - val_recall: 0.5185\n",
      "Epoch 7/100\n",
      "1383/1383 - 43s - loss: 1.1816 - accuracy: 0.5271 - precision: 0.5502 - recall: 0.3847 - val_loss: 4.9445 - val_accuracy: 0.2761 - val_precision: 0.2771 - val_recall: 0.2542\n",
      "Epoch 8/100\n",
      "1383/1383 - 44s - loss: 1.1797 - accuracy: 0.5221 - precision: 0.5538 - recall: 0.3905 - val_loss: 1.4743 - val_accuracy: 0.4966 - val_precision: 0.4954 - val_recall: 0.4579\n",
      "Epoch 9/100\n",
      "1383/1383 - 44s - loss: 1.1569 - accuracy: 0.5148 - precision: 0.5461 - recall: 0.3941 - val_loss: 1.3477 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 10/100\n",
      "1383/1383 - 45s - loss: 1.1644 - accuracy: 0.5278 - precision: 0.5417 - recall: 0.3854 - val_loss: 1.6092 - val_accuracy: 0.5185 - val_precision: 0.5164 - val_recall: 0.5051\n",
      "Epoch 11/100\n",
      "1383/1383 - 44s - loss: 1.1339 - accuracy: 0.5358 - precision: 0.5543 - recall: 0.4172 - val_loss: 1.1613 - val_accuracy: 0.5455 - val_precision: 0.5427 - val_recall: 0.5354\n",
      "Epoch 12/100\n",
      "1383/1383 - 45s - loss: 1.1318 - accuracy: 0.5343 - precision: 0.5649 - recall: 0.4027 - val_loss: 1.5821 - val_accuracy: 0.4848 - val_precision: 0.4930 - val_recall: 0.4731\n",
      "Epoch 13/100\n",
      "1383/1383 - 45s - loss: 1.1325 - accuracy: 0.5358 - precision: 0.5524 - recall: 0.3962 - val_loss: 1.3132 - val_accuracy: 0.5269 - val_precision: 0.5333 - val_recall: 0.5118\n",
      "Epoch 14/100\n",
      "1383/1383 - 45s - loss: 1.1322 - accuracy: 0.5307 - precision: 0.5679 - recall: 0.4172 - val_loss: 1.1960 - val_accuracy: 0.5421 - val_precision: 0.5472 - val_recall: 0.5370\n",
      "Epoch 15/100\n",
      "1383/1383 - 45s - loss: 1.1148 - accuracy: 0.5416 - precision: 0.5632 - recall: 0.4187 - val_loss: 1.1604 - val_accuracy: 0.5438 - val_precision: 0.5391 - val_recall: 0.5219\n",
      "Epoch 16/100\n",
      "1383/1383 - 45s - loss: 1.1236 - accuracy: 0.5430 - precision: 0.5635 - recall: 0.4201 - val_loss: 1.1425 - val_accuracy: 0.5488 - val_precision: 0.5514 - val_recall: 0.5152\n",
      "Epoch 17/100\n",
      "1383/1383 - 45s - loss: 1.1290 - accuracy: 0.5488 - precision: 0.5662 - recall: 0.4266 - val_loss: 1.4400 - val_accuracy: 0.4293 - val_precision: 0.4812 - val_recall: 0.3670\n",
      "Epoch 18/100\n",
      "1383/1383 - 46s - loss: 1.1121 - accuracy: 0.5546 - precision: 0.5601 - recall: 0.4179 - val_loss: 1.1353 - val_accuracy: 0.5236 - val_precision: 0.5331 - val_recall: 0.5017\n",
      "Epoch 19/100\n",
      "1383/1383 - 45s - loss: 1.1221 - accuracy: 0.5445 - precision: 0.5615 - recall: 0.4158 - val_loss: 1.4712 - val_accuracy: 0.5051 - val_precision: 0.5115 - val_recall: 0.4882\n",
      "Epoch 20/100\n",
      "1383/1383 - 45s - loss: 1.1029 - accuracy: 0.5481 - precision: 0.5719 - recall: 0.4172 - val_loss: 1.2844 - val_accuracy: 0.5269 - val_precision: 0.5249 - val_recall: 0.5152\n",
      "Epoch 21/100\n",
      "1383/1383 - 45s - loss: 1.1065 - accuracy: 0.5503 - precision: 0.5461 - recall: 0.4158 - val_loss: 1.3421 - val_accuracy: 0.5505 - val_precision: 0.5497 - val_recall: 0.5488\n",
      "Epoch 22/100\n",
      "1383/1383 - 45s - loss: 1.1063 - accuracy: 0.5582 - precision: 0.5657 - recall: 0.4512 - val_loss: 1.2329 - val_accuracy: 0.4798 - val_precision: 0.5156 - val_recall: 0.4175\n",
      "Epoch 23/100\n",
      "1383/1383 - 46s - loss: 1.1060 - accuracy: 0.5503 - precision: 0.5681 - recall: 0.4223 - val_loss: 1.6206 - val_accuracy: 0.5303 - val_precision: 0.5119 - val_recall: 0.3249\n",
      "Epoch 24/100\n",
      "1383/1383 - 46s - loss: 1.1033 - accuracy: 0.5625 - precision: 0.5690 - recall: 0.4324 - val_loss: 1.2107 - val_accuracy: 0.5084 - val_precision: 0.5128 - val_recall: 0.4714\n",
      "Epoch 25/100\n",
      "1383/1383 - 46s - loss: 1.0917 - accuracy: 0.5633 - precision: 0.5675 - recall: 0.4649 - val_loss: 1.1557 - val_accuracy: 0.5488 - val_precision: 0.5493 - val_recall: 0.5438\n",
      "Epoch 26/100\n",
      "1383/1383 - 46s - loss: 1.0828 - accuracy: 0.5611 - precision: 0.5512 - recall: 0.4281 - val_loss: 1.1516 - val_accuracy: 0.5286 - val_precision: 0.5281 - val_recall: 0.5067\n",
      "Epoch 27/100\n",
      "1383/1383 - 45s - loss: 1.0850 - accuracy: 0.5597 - precision: 0.5692 - recall: 0.4700 - val_loss: 1.4191 - val_accuracy: 0.4545 - val_precision: 0.4505 - val_recall: 0.4057\n",
      "Epoch 28/100\n",
      "1383/1383 - 46s - loss: 1.0788 - accuracy: 0.5633 - precision: 0.5574 - recall: 0.4845 - val_loss: 1.1347 - val_accuracy: 0.3822 - val_precision: 0.6033 - val_recall: 0.1229\n",
      "Epoch 29/100\n",
      "1383/1383 - 45s - loss: 1.0777 - accuracy: 0.5582 - precision: 0.5626 - recall: 0.4678 - val_loss: 1.7197 - val_accuracy: 0.4899 - val_precision: 0.4905 - val_recall: 0.4781\n",
      "Epoch 30/100\n",
      "1383/1383 - 46s - loss: 1.0699 - accuracy: 0.5640 - precision: 0.5624 - recall: 0.4758 - val_loss: 1.3036 - val_accuracy: 0.4983 - val_precision: 0.5043 - val_recall: 0.4933\n",
      "Epoch 31/100\n",
      "1383/1383 - 49s - loss: 1.0728 - accuracy: 0.5611 - precision: 0.5639 - recall: 0.4946 - val_loss: 1.2618 - val_accuracy: 0.5370 - val_precision: 0.5383 - val_recall: 0.5320\n",
      "Epoch 32/100\n",
      "1383/1383 - 50s - loss: 1.0660 - accuracy: 0.5625 - precision: 0.5640 - recall: 0.4620 - val_loss: 1.1267 - val_accuracy: 0.5505 - val_precision: 0.5502 - val_recall: 0.2306\n",
      "Epoch 33/100\n",
      "1383/1383 - 48s - loss: 1.0702 - accuracy: 0.5640 - precision: 0.5594 - recall: 0.5040 - val_loss: 1.3964 - val_accuracy: 0.5067 - val_precision: 0.5080 - val_recall: 0.4815\n",
      "Epoch 34/100\n",
      "1383/1383 - 46s - loss: 1.0645 - accuracy: 0.5633 - precision: 0.5786 - recall: 0.4736 - val_loss: 1.2118 - val_accuracy: 0.5286 - val_precision: 0.5281 - val_recall: 0.5067\n",
      "Epoch 35/100\n",
      "1383/1383 - 46s - loss: 1.0595 - accuracy: 0.5604 - precision: 0.5627 - recall: 0.4606 - val_loss: 1.2737 - val_accuracy: 0.5202 - val_precision: 0.5215 - val_recall: 0.5101\n",
      "Epoch 36/100\n",
      "1383/1383 - 46s - loss: 1.0559 - accuracy: 0.5640 - precision: 0.5620 - recall: 0.5278 - val_loss: 1.1635 - val_accuracy: 0.5505 - val_precision: 0.4954 - val_recall: 0.0909\n",
      "Epoch 37/100\n",
      "1383/1383 - 46s - loss: 1.0507 - accuracy: 0.5640 - precision: 0.5599 - recall: 0.5445 - val_loss: 1.2645 - val_accuracy: 0.2609 - val_precision: 0.2571 - val_recall: 0.2441\n",
      "Epoch 38/100\n",
      "1383/1383 - 46s - loss: 1.0487 - accuracy: 0.5618 - precision: 0.5620 - recall: 0.4816 - val_loss: 1.4004 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 39/100\n",
      "1383/1383 - 46s - loss: 1.0456 - accuracy: 0.5640 - precision: 0.5585 - recall: 0.5177 - val_loss: 1.4945 - val_accuracy: 0.3266 - val_precision: 0.6500 - val_recall: 0.1094\n",
      "Epoch 40/100\n",
      "1383/1383 - 46s - loss: 1.0452 - accuracy: 0.5633 - precision: 0.5606 - recall: 0.4982 - val_loss: 1.8335 - val_accuracy: 0.4714 - val_precision: 0.1837 - val_recall: 0.0303\n",
      "Epoch 41/100\n",
      "1383/1383 - 47s - loss: 1.0486 - accuracy: 0.5618 - precision: 0.5562 - recall: 0.5047 - val_loss: 1.1416 - val_accuracy: 0.5488 - val_precision: 0.5516 - val_recall: 0.5488\n",
      "Epoch 42/100\n",
      "1383/1383 - 46s - loss: 1.0443 - accuracy: 0.5625 - precision: 0.5593 - recall: 0.5249 - val_loss: 2.3683 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 43/100\n",
      "1383/1383 - 47s - loss: 1.0414 - accuracy: 0.5597 - precision: 0.5659 - recall: 0.5033 - val_loss: 1.0631 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 44/100\n",
      "1383/1383 - 45s - loss: 1.0361 - accuracy: 0.5640 - precision: 0.5604 - recall: 0.5235 - val_loss: 1.1169 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 45/100\n",
      "1383/1383 - 45s - loss: 1.0373 - accuracy: 0.5640 - precision: 0.5625 - recall: 0.5300 - val_loss: 1.1374 - val_accuracy: 0.5438 - val_precision: 0.5447 - val_recall: 0.5337\n",
      "Epoch 46/100\n",
      "1383/1383 - 49s - loss: 1.0358 - accuracy: 0.5640 - precision: 0.5590 - recall: 0.5069 - val_loss: 1.0563 - val_accuracy: 0.5505 - val_precision: 1.0000 - val_recall: 0.0017\n",
      "Epoch 47/100\n",
      "1383/1383 - 47s - loss: 1.0364 - accuracy: 0.5625 - precision: 0.5604 - recall: 0.5098 - val_loss: 1.8316 - val_accuracy: 0.5505 - val_precision: 0.5714 - val_recall: 0.1953\n",
      "Epoch 48/100\n",
      "1383/1383 - 45s - loss: 1.0440 - accuracy: 0.5597 - precision: 0.5643 - recall: 0.4982 - val_loss: 1.5326 - val_accuracy: 0.4562 - val_precision: 0.4679 - val_recall: 0.4411\n",
      "Epoch 49/100\n",
      "1383/1383 - 46s - loss: 1.0406 - accuracy: 0.5640 - precision: 0.5591 - recall: 0.4960 - val_loss: 1.3220 - val_accuracy: 0.5505 - val_precision: 0.5519 - val_recall: 0.1700\n",
      "Epoch 50/100\n",
      "1383/1383 - 45s - loss: 1.0249 - accuracy: 0.5640 - precision: 0.5660 - recall: 0.5242 - val_loss: 1.2240 - val_accuracy: 0.5421 - val_precision: 0.5120 - val_recall: 0.1431\n",
      "Epoch 51/100\n",
      "1383/1383 - 45s - loss: 1.0238 - accuracy: 0.5640 - precision: 0.5589 - recall: 0.5387 - val_loss: 1.5875 - val_accuracy: 0.5505 - val_precision: 0.5385 - val_recall: 0.1414\n",
      "Epoch 52/100\n",
      "1383/1383 - 46s - loss: 1.0263 - accuracy: 0.5640 - precision: 0.5638 - recall: 0.5141 - val_loss: 1.5576 - val_accuracy: 0.2525 - val_precision: 0.1995 - val_recall: 0.1481\n",
      "Epoch 53/100\n",
      "1383/1383 - 47s - loss: 1.0267 - accuracy: 0.5640 - precision: 0.5586 - recall: 0.5271 - val_loss: 2.6863 - val_accuracy: 0.4747 - val_precision: 0.4788 - val_recall: 0.4562\n",
      "Epoch 54/100\n",
      "1383/1383 - 45s - loss: 1.0209 - accuracy: 0.5640 - precision: 0.5611 - recall: 0.5343 - val_loss: 1.1163 - val_accuracy: 0.5303 - val_precision: 0.5269 - val_recall: 0.4949\n",
      "Epoch 55/100\n",
      "1383/1383 - 46s - loss: 1.0191 - accuracy: 0.5640 - precision: 0.5596 - recall: 0.4953 - val_loss: 1.0809 - val_accuracy: 0.4663 - val_precision: 0.5040 - val_recall: 0.3165\n",
      "Epoch 56/100\n",
      "1383/1383 - 46s - loss: 1.0176 - accuracy: 0.5640 - precision: 0.5596 - recall: 0.5329 - val_loss: 119.6927 - val_accuracy: 0.3047 - val_precision: 0.3034 - val_recall: 0.3013\n",
      "Epoch 57/100\n",
      "1383/1383 - 46s - loss: 1.0155 - accuracy: 0.5640 - precision: 0.5642 - recall: 0.5083 - val_loss: 1.5025 - val_accuracy: 0.5084 - val_precision: 0.5104 - val_recall: 0.4949\n",
      "Epoch 58/100\n",
      "1383/1383 - 47s - loss: 1.0144 - accuracy: 0.5640 - precision: 0.5608 - recall: 0.5300 - val_loss: 1.1163 - val_accuracy: 0.5269 - val_precision: 0.5392 - val_recall: 0.4865\n",
      "Epoch 59/100\n",
      "1383/1383 - 45s - loss: 1.0135 - accuracy: 0.5640 - precision: 0.5592 - recall: 0.5257 - val_loss: 1.4840 - val_accuracy: 0.3468 - val_precision: 0.3424 - val_recall: 0.2980\n",
      "Epoch 60/100\n",
      "1383/1383 - 45s - loss: 1.0110 - accuracy: 0.5618 - precision: 0.5739 - recall: 0.4801 - val_loss: 1.2027 - val_accuracy: 0.5505 - val_precision: 0.5644 - val_recall: 0.4276\n",
      "Epoch 61/100\n",
      "1383/1383 - 45s - loss: 1.0138 - accuracy: 0.5640 - precision: 0.5626 - recall: 0.5423 - val_loss: 2.3373 - val_accuracy: 0.3788 - val_precision: 0.4029 - val_recall: 0.3249\n",
      "Epoch 62/100\n",
      "1383/1383 - 46s - loss: 1.0124 - accuracy: 0.5640 - precision: 0.5681 - recall: 0.5098 - val_loss: 1.2071 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 63/100\n",
      "1383/1383 - 45s - loss: 1.0068 - accuracy: 0.5640 - precision: 0.5643 - recall: 0.5141 - val_loss: 1.0387 - val_accuracy: 0.5421 - val_precision: 0.5442 - val_recall: 0.5286\n",
      "Epoch 64/100\n",
      "1383/1383 - 45s - loss: 1.0013 - accuracy: 0.5640 - precision: 0.5660 - recall: 0.5271 - val_loss: 4.1829 - val_accuracy: 0.5000 - val_precision: 0.5035 - val_recall: 0.4832\n",
      "Epoch 65/100\n",
      "1383/1383 - 46s - loss: 1.0062 - accuracy: 0.5640 - precision: 0.5646 - recall: 0.5307 - val_loss: 1.0578 - val_accuracy: 0.5303 - val_precision: 0.5351 - val_recall: 0.4882\n",
      "Epoch 66/100\n",
      "1383/1383 - 46s - loss: 1.0057 - accuracy: 0.5640 - precision: 0.5635 - recall: 0.5517 - val_loss: 1.0610 - val_accuracy: 0.5320 - val_precision: 0.5333 - val_recall: 0.4444\n",
      "Epoch 67/100\n",
      "1383/1383 - 45s - loss: 1.0023 - accuracy: 0.5640 - precision: 0.5585 - recall: 0.5112 - val_loss: 9.6005 - val_accuracy: 0.3973 - val_precision: 0.3935 - val_recall: 0.3670\n",
      "Epoch 68/100\n",
      "1383/1383 - 46s - loss: 1.0046 - accuracy: 0.5625 - precision: 0.5606 - recall: 0.5249 - val_loss: 19.2223 - val_accuracy: 0.2593 - val_precision: 0.2601 - val_recall: 0.2593\n",
      "Epoch 69/100\n",
      "1383/1383 - 48s - loss: 1.0005 - accuracy: 0.5640 - precision: 0.5620 - recall: 0.5474 - val_loss: 57.8719 - val_accuracy: 0.2441 - val_precision: 0.2445 - val_recall: 0.2441\n",
      "Epoch 70/100\n",
      "1383/1383 - 46s - loss: 1.0047 - accuracy: 0.5640 - precision: 0.5637 - recall: 0.5597 - val_loss: 1.9758 - val_accuracy: 0.3586 - val_precision: 0.3618 - val_recall: 0.3569\n",
      "Epoch 71/100\n",
      "1383/1383 - 46s - loss: 1.0022 - accuracy: 0.5640 - precision: 0.5619 - recall: 0.5546 - val_loss: 1.0982 - val_accuracy: 0.5505 - val_precision: 0.5732 - val_recall: 0.3822\n",
      "Epoch 72/100\n",
      "1383/1383 - 46s - loss: 0.9991 - accuracy: 0.5640 - precision: 0.5725 - recall: 0.5025 - val_loss: 2.3274 - val_accuracy: 0.3165 - val_precision: 0.2876 - val_recall: 0.2576\n",
      "Epoch 73/100\n",
      "1383/1383 - 46s - loss: 1.0002 - accuracy: 0.5640 - precision: 0.5645 - recall: 0.5098 - val_loss: 1.0083 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 74/100\n",
      "1383/1383 - 45s - loss: 0.9991 - accuracy: 0.5640 - precision: 0.5691 - recall: 0.5329 - val_loss: 1.0089 - val_accuracy: 0.5505 - val_precision: 0.5591 - val_recall: 0.3822\n",
      "Epoch 75/100\n",
      "1383/1383 - 46s - loss: 1.0019 - accuracy: 0.5633 - precision: 0.5636 - recall: 0.5322 - val_loss: 1.0115 - val_accuracy: 0.5488 - val_precision: 0.5488 - val_recall: 0.5488\n",
      "Epoch 76/100\n",
      "1383/1383 - 47s - loss: 0.9968 - accuracy: 0.5640 - precision: 0.5620 - recall: 0.5503 - val_loss: 12.8252 - val_accuracy: 0.5505 - val_precision: 0.5514 - val_recall: 0.5505\n",
      "Epoch 77/100\n",
      "1383/1383 - 48s - loss: 1.0003 - accuracy: 0.5618 - precision: 0.5670 - recall: 0.5322 - val_loss: 2.8820 - val_accuracy: 0.5370 - val_precision: 0.5360 - val_recall: 0.5269\n",
      "Epoch 78/100\n",
      "1383/1383 - 46s - loss: 1.0003 - accuracy: 0.5640 - precision: 0.5665 - recall: 0.5387 - val_loss: 6.6117 - val_accuracy: 0.1919 - val_precision: 0.1919 - val_recall: 0.1919\n",
      "Epoch 79/100\n",
      "1383/1383 - 46s - loss: 0.9979 - accuracy: 0.5640 - precision: 0.5637 - recall: 0.5568 - val_loss: 3.9178 - val_accuracy: 0.3889 - val_precision: 0.3738 - val_recall: 0.3316\n",
      "Epoch 80/100\n",
      "1383/1383 - 45s - loss: 1.0035 - accuracy: 0.5640 - precision: 0.5596 - recall: 0.5090 - val_loss: 1.0173 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 81/100\n",
      "1383/1383 - 47s - loss: 0.9994 - accuracy: 0.5640 - precision: 0.5633 - recall: 0.5597 - val_loss: 1.0565 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 82/100\n",
      "1383/1383 - 47s - loss: 1.0008 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 1.0492 - val_accuracy: 0.5135 - val_precision: 0.5218 - val_recall: 0.3620\n",
      "Epoch 83/100\n",
      "1383/1383 - 48s - loss: 0.9981 - accuracy: 0.5640 - precision: 0.5685 - recall: 0.5343 - val_loss: 5.5706 - val_accuracy: 0.3064 - val_precision: 0.3157 - val_recall: 0.2710\n",
      "Epoch 84/100\n",
      "1383/1383 - 48s - loss: 0.9972 - accuracy: 0.5640 - precision: 0.5637 - recall: 0.5633 - val_loss: 1.0164 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 85/100\n",
      "1383/1383 - 49s - loss: 1.0047 - accuracy: 0.5640 - precision: 0.5648 - recall: 0.5199 - val_loss: 1.0155 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 86/100\n",
      "1383/1383 - 47s - loss: 1.0006 - accuracy: 0.5640 - precision: 0.5623 - recall: 0.5387 - val_loss: 0.9974 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 87/100\n",
      "1383/1383 - 46s - loss: 0.9964 - accuracy: 0.5640 - precision: 0.5632 - recall: 0.5575 - val_loss: 1.0302 - val_accuracy: 0.5354 - val_precision: 0.2500 - val_recall: 0.0017\n",
      "Epoch 88/100\n",
      "1383/1383 - 46s - loss: 0.9956 - accuracy: 0.5640 - precision: 0.5647 - recall: 0.5336 - val_loss: 1.0411 - val_accuracy: 0.5135 - val_precision: 0.5204 - val_recall: 0.3215\n",
      "Epoch 89/100\n",
      "1383/1383 - 45s - loss: 0.9965 - accuracy: 0.5640 - precision: 0.5634 - recall: 0.5625 - val_loss: 3.1111 - val_accuracy: 0.3771 - val_precision: 0.3653 - val_recall: 0.3013\n",
      "Epoch 90/100\n",
      "1383/1383 - 46s - loss: 0.9965 - accuracy: 0.5640 - precision: 0.5691 - recall: 0.5148 - val_loss: 1.6802 - val_accuracy: 0.2643 - val_precision: 0.2667 - val_recall: 0.2424\n",
      "Epoch 91/100\n",
      "1383/1383 - 46s - loss: 0.9982 - accuracy: 0.5640 - precision: 0.5649 - recall: 0.5380 - val_loss: 1.1969 - val_accuracy: 0.4613 - val_precision: 0.4681 - val_recall: 0.4444\n",
      "Epoch 92/100\n",
      "1383/1383 - 46s - loss: 0.9982 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5257 - val_loss: 1.0084 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 93/100\n",
      "1383/1383 - 48s - loss: 0.9975 - accuracy: 0.5640 - precision: 0.5627 - recall: 0.5611 - val_loss: 1.0311 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 94/100\n",
      "1383/1383 - 47s - loss: 0.9980 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 1.0438 - val_accuracy: 0.5118 - val_precision: 0.4842 - val_recall: 0.1801\n",
      "Epoch 95/100\n",
      "1383/1383 - 45s - loss: 0.9977 - accuracy: 0.5640 - precision: 0.5671 - recall: 0.5380 - val_loss: 1.0435 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 96/100\n",
      "1383/1383 - 46s - loss: 0.9967 - accuracy: 0.5640 - precision: 0.5649 - recall: 0.5069 - val_loss: 1.0014 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 97/100\n",
      "1383/1383 - 46s - loss: 0.9971 - accuracy: 0.5640 - precision: 0.5633 - recall: 0.5597 - val_loss: 1.0343 - val_accuracy: 0.5404 - val_precision: 0.5415 - val_recall: 0.1869\n",
      "Epoch 98/100\n",
      "1383/1383 - 46s - loss: 0.9958 - accuracy: 0.5640 - precision: 0.5621 - recall: 0.5531 - val_loss: 1.0079 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 99/100\n",
      "1383/1383 - 46s - loss: 0.9967 - accuracy: 0.5640 - precision: 0.5639 - recall: 0.5618 - val_loss: 1.2237 - val_accuracy: 0.5017 - val_precision: 0.4889 - val_recall: 0.3350\n",
      "Epoch 100/100\n",
      "1383/1383 - 46s - loss: 0.9962 - accuracy: 0.5640 - precision: 0.5639 - recall: 0.5618 - val_loss: 1.0172 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x238dbb8abe0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model_filter_number = 70\n",
    "model_learning_rate = 1e-5\n",
    "input_res = 224\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# Load training data from lightfield .png files:\n",
    "print(\"Loading lightfield paths...\")\n",
    "\n",
    "dir_lf_images = \"C:\\\\Users\\\\muell\\\\Desktop\\\\1part_1background_halfbaseline\"\n",
    "list_IDs = get_list_ids(dir_lf_images)\n",
    "\n",
    "print(\"Done loading lightfield paths.\")\n",
    "fraction = np.int(len(list_IDs)*0.7)\n",
    "list_IDs_train, list_IDs_test = list_IDs[:fraction], list_IDs[fraction:]\n",
    "\n",
    "model = define_epidef(input_res, input_res)\n",
    "\n",
    "x_train, y_train = load_lightfield_data(list_IDs_train, input_res)\n",
    "x_test, y_test = load_lightfield_data(list_IDs_test, input_res)\n",
    "\n",
    "y_train_cat = tf.one_hot(y_train, NUM_CLASSES)\n",
    "y_test_cat = tf.one_hot(y_test, NUM_CLASSES)\n",
    "x_train = tf.convert_to_tensor(x_train)\n",
    "x_test = tf.convert_to_tensor(x_test)\n",
    "\n",
    "\n",
    "model.fit(x=x_train, y=y_train_cat,\n",
    "          epochs=100,\n",
    "          max_queue_size=10,\n",
    "          initial_epoch=0,\n",
    "          verbose=2,\n",
    "          batch_size=1,\n",
    "          validation_data=(x_test, y_test_cat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1383/1383 - 45s - loss: 0.9993 - accuracy: 0.5640 - precision: 0.5652 - recall: 0.5452 - val_loss: 65.3284 - val_accuracy: 0.2997 - val_precision: 0.3002 - val_recall: 0.2997\n",
      "Epoch 2/100\n",
      "1383/1383 - 45s - loss: 1.0021 - accuracy: 0.5640 - precision: 0.5713 - recall: 0.5155 - val_loss: 1.0185 - val_accuracy: 0.5505 - val_precision: 0.5683 - val_recall: 0.1330\n",
      "Epoch 3/100\n",
      "1383/1383 - 45s - loss: 0.9981 - accuracy: 0.5640 - precision: 0.5652 - recall: 0.5488 - val_loss: 1.0158 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 4/100\n",
      "1383/1383 - 45s - loss: 0.9965 - accuracy: 0.5640 - precision: 0.5625 - recall: 0.5495 - val_loss: 1.1034 - val_accuracy: 0.4158 - val_precision: 0.5020 - val_recall: 0.2088\n",
      "Epoch 5/100\n",
      "1383/1383 - 45s - loss: 0.9979 - accuracy: 0.5640 - precision: 0.5632 - recall: 0.5315 - val_loss: 1.0084 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 6/100\n",
      "1383/1383 - 46s - loss: 0.9937 - accuracy: 0.5640 - precision: 0.5648 - recall: 0.5423 - val_loss: 1.0147 - val_accuracy: 0.5505 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1383/1383 - 46s - loss: 0.9958 - accuracy: 0.5640 - precision: 0.5643 - recall: 0.5488 - val_loss: 4.8075 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 8/100\n",
      "1383/1383 - 46s - loss: 0.9969 - accuracy: 0.5640 - precision: 0.5623 - recall: 0.5582 - val_loss: 1.0073 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 9/100\n",
      "1383/1383 - 46s - loss: 0.9939 - accuracy: 0.5640 - precision: 0.5632 - recall: 0.5474 - val_loss: 1.0523 - val_accuracy: 0.5505 - val_precision: 0.7222 - val_recall: 0.0219\n",
      "Epoch 10/100\n",
      "1383/1383 - 46s - loss: 0.9967 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 1.0098 - val_accuracy: 0.5505 - val_precision: 0.5430 - val_recall: 0.5000\n",
      "Epoch 11/100\n",
      "1383/1383 - 47s - loss: 0.9961 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5575 - val_loss: 1.0025 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 12/100\n",
      "1383/1383 - 46s - loss: 0.9931 - accuracy: 0.5640 - precision: 0.5641 - recall: 0.5633 - val_loss: 1.0196 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 13/100\n",
      "1383/1383 - 46s - loss: 0.9947 - accuracy: 0.5640 - precision: 0.5632 - recall: 0.5445 - val_loss: 1.0773 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 14/100\n",
      "1383/1383 - 46s - loss: 0.9941 - accuracy: 0.5640 - precision: 0.5645 - recall: 0.5633 - val_loss: 1.0378 - val_accuracy: 0.4579 - val_precision: 0.4167 - val_recall: 0.0084\n",
      "Epoch 15/100\n",
      "1383/1383 - 46s - loss: 0.9966 - accuracy: 0.5640 - precision: 0.5643 - recall: 0.5329 - val_loss: 1.2228 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 16/100\n",
      "1383/1383 - 46s - loss: 0.9980 - accuracy: 0.5640 - precision: 0.5623 - recall: 0.5582 - val_loss: 1.2443 - val_accuracy: 0.4360 - val_precision: 0.4401 - val_recall: 0.4024\n",
      "Epoch 17/100\n",
      "1383/1383 - 46s - loss: 0.9978 - accuracy: 0.5597 - precision: 0.5665 - recall: 0.5481 - val_loss: 1.0108 - val_accuracy: 0.5505 - val_precision: 0.6339 - val_recall: 0.1195\n",
      "Epoch 18/100\n",
      "1383/1383 - 46s - loss: 0.9956 - accuracy: 0.5640 - precision: 0.5644 - recall: 0.5611 - val_loss: 0.9966 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 19/100\n",
      "1383/1383 - 46s - loss: 0.9943 - accuracy: 0.5611 - precision: 0.5671 - recall: 0.5380 - val_loss: 4.2343 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 20/100\n",
      "1383/1383 - 46s - loss: 0.9962 - accuracy: 0.5640 - precision: 0.5624 - recall: 0.5575 - val_loss: 1.0117 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 21/100\n",
      "1383/1383 - 46s - loss: 0.9951 - accuracy: 0.5640 - precision: 0.5638 - recall: 0.5625 - val_loss: 1.0308 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 22/100\n",
      "1383/1383 - 46s - loss: 0.9963 - accuracy: 0.5640 - precision: 0.5635 - recall: 0.5611 - val_loss: 1.2156 - val_accuracy: 0.1919 - val_precision: 0.2222 - val_recall: 0.0135\n",
      "Epoch 23/100\n",
      "1383/1383 - 46s - loss: 0.9945 - accuracy: 0.5640 - precision: 0.5634 - recall: 0.5589 - val_loss: 1.0087 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 24/100\n",
      "1383/1383 - 46s - loss: 0.9917 - accuracy: 0.5640 - precision: 0.5630 - recall: 0.5524 - val_loss: 2.2623 - val_accuracy: 0.1987 - val_precision: 0.1918 - val_recall: 0.1801\n",
      "Epoch 25/100\n",
      "1383/1383 - 46s - loss: 0.9954 - accuracy: 0.5640 - precision: 0.5630 - recall: 0.5618 - val_loss: 1.4467 - val_accuracy: 0.2391 - val_precision: 0.2091 - val_recall: 0.1465\n",
      "Epoch 26/100\n",
      "1383/1383 - 46s - loss: 0.9958 - accuracy: 0.5640 - precision: 0.5638 - recall: 0.5589 - val_loss: 1.0025 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 27/100\n",
      "1383/1383 - 46s - loss: 0.9967 - accuracy: 0.5640 - precision: 0.5645 - recall: 0.5633 - val_loss: 1.2189 - val_accuracy: 0.3956 - val_precision: 0.4096 - val_recall: 0.2862\n",
      "Epoch 28/100\n",
      "1383/1383 - 46s - loss: 0.9953 - accuracy: 0.5640 - precision: 0.5661 - recall: 0.5416 - val_loss: 1.4882 - val_accuracy: 0.4226 - val_precision: 0.4221 - val_recall: 0.4108\n",
      "Epoch 29/100\n",
      "1383/1383 - 46s - loss: 0.9939 - accuracy: 0.5640 - precision: 0.5628 - recall: 0.5510 - val_loss: 1.0239 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 30/100\n",
      "1383/1383 - 46s - loss: 0.9981 - accuracy: 0.5640 - precision: 0.5641 - recall: 0.5503 - val_loss: 1.0050 - val_accuracy: 0.5505 - val_precision: 0.5442 - val_recall: 0.2694\n",
      "Epoch 31/100\n",
      "1383/1383 - 45s - loss: 0.9955 - accuracy: 0.5640 - precision: 0.5632 - recall: 0.5575 - val_loss: 3.3099 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 32/100\n",
      "1383/1383 - 46s - loss: 0.9952 - accuracy: 0.5640 - precision: 0.5642 - recall: 0.5589 - val_loss: 11.0990 - val_accuracy: 0.2609 - val_precision: 0.2393 - val_recall: 0.2172\n",
      "Epoch 33/100\n",
      "1383/1383 - 46s - loss: 0.9938 - accuracy: 0.5640 - precision: 0.5632 - recall: 0.5221 - val_loss: 1005.4050 - val_accuracy: 0.2037 - val_precision: 0.2040 - val_recall: 0.2037\n",
      "Epoch 34/100\n",
      "1383/1383 - 46s - loss: 1.0000 - accuracy: 0.5640 - precision: 0.5665 - recall: 0.5481 - val_loss: 1.0268 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 35/100\n",
      "1383/1383 - 46s - loss: 0.9979 - accuracy: 0.5640 - precision: 0.5638 - recall: 0.5589 - val_loss: 1.0238 - val_accuracy: 0.5505 - val_precision: 0.5584 - val_recall: 0.5152\n",
      "Epoch 36/100\n",
      "1383/1383 - 46s - loss: 0.9952 - accuracy: 0.5640 - precision: 0.5616 - recall: 0.5271 - val_loss: 1.0117 - val_accuracy: 0.5505 - val_precision: 0.5507 - val_recall: 0.5118\n",
      "Epoch 37/100\n",
      "1383/1383 - 46s - loss: 0.9912 - accuracy: 0.5640 - precision: 0.5734 - recall: 0.4996 - val_loss: 1.0089 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 38/100\n",
      "1383/1383 - 46s - loss: 0.9951 - accuracy: 0.5640 - precision: 0.5597 - recall: 0.5423 - val_loss: 1.0001 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 39/100\n",
      "1383/1383 - 46s - loss: 0.9959 - accuracy: 0.5640 - precision: 0.5583 - recall: 0.5466 - val_loss: 1.0185 - val_accuracy: 0.5505 - val_precision: 0.6250 - val_recall: 0.0337\n",
      "Epoch 40/100\n",
      "1383/1383 - 46s - loss: 0.9940 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 19.4418 - val_accuracy: 0.3114 - val_precision: 0.3120 - val_recall: 0.3114\n",
      "Epoch 41/100\n",
      "1383/1383 - 46s - loss: 0.9948 - accuracy: 0.5640 - precision: 0.5633 - recall: 0.5503 - val_loss: 2.0553 - val_accuracy: 0.3249 - val_precision: 0.3047 - val_recall: 0.2811\n",
      "Epoch 42/100\n",
      "1383/1383 - 46s - loss: 0.9967 - accuracy: 0.5640 - precision: 0.5639 - recall: 0.5553 - val_loss: 1.0713 - val_accuracy: 0.5455 - val_precision: 0.5600 - val_recall: 0.2828\n",
      "Epoch 43/100\n",
      "1383/1383 - 46s - loss: 1.0002 - accuracy: 0.5633 - precision: 0.5663 - recall: 0.5495 - val_loss: 1.0093 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 44/100\n",
      "1383/1383 - 45s - loss: 0.9962 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 3.9047 - val_accuracy: 0.3114 - val_precision: 0.3103 - val_recall: 0.3098\n",
      "Epoch 45/100\n",
      "1383/1383 - 45s - loss: 0.9947 - accuracy: 0.5640 - precision: 0.5627 - recall: 0.5517 - val_loss: 0.9982 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 46/100\n",
      "1383/1383 - 46s - loss: 0.9947 - accuracy: 0.5640 - precision: 0.5623 - recall: 0.5322 - val_loss: 1.2200 - val_accuracy: 0.5320 - val_precision: 0.5219 - val_recall: 0.4613\n",
      "Epoch 47/100\n",
      "1383/1383 - 49s - loss: 0.9931 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 1.0789 - val_accuracy: 0.3889 - val_precision: 0.5735 - val_recall: 0.2037\n",
      "Epoch 48/100\n",
      "1383/1383 - 49s - loss: 0.9954 - accuracy: 0.5640 - precision: 0.5637 - recall: 0.5278 - val_loss: 7.4275 - val_accuracy: 0.3232 - val_precision: 0.3049 - val_recall: 0.2710\n",
      "Epoch 49/100\n",
      "1383/1383 - 47s - loss: 0.9972 - accuracy: 0.5640 - precision: 0.5684 - recall: 0.5315 - val_loss: 1.1325 - val_accuracy: 0.3721 - val_precision: 0.3595 - val_recall: 0.1465\n",
      "Epoch 50/100\n",
      "1383/1383 - 47s - loss: 0.9956 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 9.2089 - val_accuracy: 0.2424 - val_precision: 0.1894 - val_recall: 0.1566\n",
      "Epoch 51/100\n",
      "1383/1383 - 47s - loss: 0.9951 - accuracy: 0.5640 - precision: 0.5607 - recall: 0.5445 - val_loss: 1.0003 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 52/100\n",
      "1383/1383 - 46s - loss: 0.9966 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 1.0081 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 53/100\n",
      "1383/1383 - 46s - loss: 0.9952 - accuracy: 0.5640 - precision: 0.5620 - recall: 0.5575 - val_loss: 1.6807 - val_accuracy: 0.4310 - val_precision: 0.1238 - val_recall: 0.0219\n",
      "Epoch 54/100\n",
      "1383/1383 - 46s - loss: 0.9971 - accuracy: 0.5640 - precision: 0.5630 - recall: 0.5589 - val_loss: 2.2278 - val_accuracy: 0.3704 - val_precision: 0.3602 - val_recall: 0.3232\n",
      "Epoch 55/100\n",
      "1383/1383 - 46s - loss: 0.9946 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 1.0090 - val_accuracy: 0.5505 - val_precision: 0.5825 - val_recall: 0.2795\n",
      "Epoch 56/100\n",
      "1383/1383 - 46s - loss: 0.9938 - accuracy: 0.5640 - precision: 0.5651 - recall: 0.5365 - val_loss: 1.0952 - val_accuracy: 0.2811 - val_precision: 0.5000 - val_recall: 0.0303\n",
      "Epoch 57/100\n",
      "1383/1383 - 46s - loss: 0.9995 - accuracy: 0.5640 - precision: 0.5635 - recall: 0.5452 - val_loss: 1.0016 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 58/100\n",
      "1383/1383 - 46s - loss: 0.9943 - accuracy: 0.5640 - precision: 0.5626 - recall: 0.5524 - val_loss: 1.0108 - val_accuracy: 0.5505 - val_precision: 0.6436 - val_recall: 0.1094\n",
      "Epoch 59/100\n",
      "1383/1383 - 45s - loss: 0.9953 - accuracy: 0.5640 - precision: 0.5631 - recall: 0.5546 - val_loss: 1.0029 - val_accuracy: 0.5505 - val_precision: 0.5517 - val_recall: 0.5303\n",
      "Epoch 60/100\n",
      "1383/1383 - 45s - loss: 0.9935 - accuracy: 0.5640 - precision: 0.5717 - recall: 0.5134 - val_loss: 0.9990 - val_accuracy: 0.5505 - val_precision: 0.5527 - val_recall: 0.5118\n",
      "Epoch 61/100\n",
      "1383/1383 - 46s - loss: 0.9954 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 1.0012 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 62/100\n",
      "1383/1383 - 46s - loss: 0.9965 - accuracy: 0.5640 - precision: 0.5626 - recall: 0.5589 - val_loss: 1.0168 - val_accuracy: 0.5505 - val_precision: 0.4054 - val_recall: 0.0253\n",
      "Epoch 63/100\n",
      "1383/1383 - 46s - loss: 0.9974 - accuracy: 0.5640 - precision: 0.5613 - recall: 0.5560 - val_loss: 1.0019 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 64/100\n",
      "1383/1383 - 45s - loss: 0.9944 - accuracy: 0.5640 - precision: 0.5613 - recall: 0.5459 - val_loss: 1.0136 - val_accuracy: 0.5505 - val_precision: 0.5124 - val_recall: 0.1734\n",
      "Epoch 65/100\n",
      "1383/1383 - 45s - loss: 0.9953 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 1.0132 - val_accuracy: 0.5505 - val_precision: 0.5373 - val_recall: 0.2912\n",
      "Epoch 66/100\n",
      "1383/1383 - 45s - loss: 0.9957 - accuracy: 0.5640 - precision: 0.5618 - recall: 0.5387 - val_loss: 1.0100 - val_accuracy: 0.5505 - val_precision: 0.5508 - val_recall: 0.5017\n",
      "Epoch 67/100\n",
      "1383/1383 - 46s - loss: 0.9962 - accuracy: 0.5640 - precision: 0.5646 - recall: 0.5495 - val_loss: 1.0067 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 68/100\n",
      "1383/1383 - 46s - loss: 0.9929 - accuracy: 0.5640 - precision: 0.5629 - recall: 0.5503 - val_loss: 1.2069 - val_accuracy: 0.4613 - val_precision: 0.4697 - val_recall: 0.4175\n",
      "Epoch 69/100\n",
      "1383/1383 - 46s - loss: 0.9941 - accuracy: 0.5640 - precision: 0.5613 - recall: 0.5560 - val_loss: 0.9988 - val_accuracy: 0.5505 - val_precision: 0.5497 - val_recall: 0.5488\n",
      "Epoch 70/100\n",
      "1383/1383 - 46s - loss: 0.9964 - accuracy: 0.5640 - precision: 0.5636 - recall: 0.5416 - val_loss: 1.0055 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 71/100\n",
      "1383/1383 - 46s - loss: 0.9942 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 1.0051 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 72/100\n",
      "1383/1383 - 46s - loss: 0.9933 - accuracy: 0.5640 - precision: 0.5629 - recall: 0.5503 - val_loss: 1.0058 - val_accuracy: 0.5505 - val_precision: 0.5497 - val_recall: 0.5488\n",
      "Epoch 73/100\n",
      "1383/1383 - 46s - loss: 0.9951 - accuracy: 0.5640 - precision: 0.5631 - recall: 0.5322 - val_loss: 1.6882 - val_accuracy: 0.4646 - val_precision: 0.4664 - val_recall: 0.4327\n",
      "Epoch 74/100\n",
      "1383/1383 - 46s - loss: 0.9981 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 10.8676 - val_accuracy: 0.4276 - val_precision: 0.4265 - val_recall: 0.3906\n",
      "Epoch 75/100\n",
      "1383/1383 - 46s - loss: 0.9970 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 1.0018 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 76/100\n",
      "1383/1383 - 46s - loss: 0.9957 - accuracy: 0.5640 - precision: 0.5633 - recall: 0.5531 - val_loss: 1.2051 - val_accuracy: 0.5017 - val_precision: 0.5053 - val_recall: 0.4848\n",
      "Epoch 77/100\n",
      "1383/1383 - 46s - loss: 0.9949 - accuracy: 0.5640 - precision: 0.5631 - recall: 0.5517 - val_loss: 1.0117 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 78/100\n",
      "1383/1383 - 46s - loss: 0.9937 - accuracy: 0.5640 - precision: 0.5637 - recall: 0.5633 - val_loss: 0.9981 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 79/100\n",
      "1383/1383 - 46s - loss: 0.9956 - accuracy: 0.5640 - precision: 0.5630 - recall: 0.5365 - val_loss: 1.9919 - val_accuracy: 0.2963 - val_precision: 0.2647 - val_recall: 0.2273\n",
      "Epoch 80/100\n",
      "1383/1383 - 46s - loss: 0.9954 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 1.0628 - val_accuracy: 0.5404 - val_precision: 0.5399 - val_recall: 0.5236\n",
      "Epoch 81/100\n",
      "1383/1383 - 45s - loss: 0.9952 - accuracy: 0.5640 - precision: 0.5637 - recall: 0.5633 - val_loss: 1.0361 - val_accuracy: 0.5505 - val_precision: 0.5497 - val_recall: 0.5488\n",
      "Epoch 82/100\n",
      "1383/1383 - 46s - loss: 0.9959 - accuracy: 0.5640 - precision: 0.5625 - recall: 0.5401 - val_loss: 1.0073 - val_accuracy: 0.5505 - val_precision: 0.5378 - val_recall: 0.4916\n",
      "Epoch 83/100\n",
      "1383/1383 - 46s - loss: 0.9939 - accuracy: 0.5640 - precision: 0.5654 - recall: 0.5437 - val_loss: 1.0220 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 84/100\n",
      "1383/1383 - 46s - loss: 0.9942 - accuracy: 0.5640 - precision: 0.5644 - recall: 0.5640 - val_loss: 1.0030 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 85/100\n",
      "1383/1383 - 46s - loss: 0.9946 - accuracy: 0.5640 - precision: 0.5653 - recall: 0.5474 - val_loss: 1.0473 - val_accuracy: 0.5505 - val_precision: 0.5497 - val_recall: 0.5488\n",
      "Epoch 86/100\n",
      "1383/1383 - 46s - loss: 0.9942 - accuracy: 0.5640 - precision: 0.5640 - recall: 0.5640 - val_loss: 0.9989 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 87/100\n",
      "1383/1383 - 45s - loss: 0.9933 - accuracy: 0.5633 - precision: 0.5665 - recall: 0.5481 - val_loss: 1.0054 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 88/100\n",
      "1383/1383 - 45s - loss: 0.9943 - accuracy: 0.5640 - precision: 0.5622 - recall: 0.5459 - val_loss: 16.9165 - val_accuracy: 0.2576 - val_precision: 0.2576 - val_recall: 0.2576\n",
      "Epoch 89/100\n",
      "1383/1383 - 45s - loss: 0.9949 - accuracy: 0.5640 - precision: 0.5613 - recall: 0.5459 - val_loss: 1.0027 - val_accuracy: 0.5505 - val_precision: 0.5505 - val_recall: 0.5505\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-dcde68f55962>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit(x=x_train, y=y_train_cat,\n\u001b[0m\u001b[0;32m      2\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train_cat,\n",
    "          epochs=100,\n",
    "          max_queue_size=10,\n",
    "          initial_epoch=0,\n",
    "          verbose=2,\n",
    "          batch_size=1,\n",
    "          validation_data=(x_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
