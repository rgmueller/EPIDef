{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization, Input\n",
    "from tensorflow.keras.backend import concatenate\n",
    "import tensorflow as tf\n",
    "from official.vision.image_classification.efficientnet import efficientnet_model\n",
    "\n",
    "\n",
    "\n",
    "def layer1_multistream(res_x, res_y, num_cams, filter_num):\n",
    "    \"\"\"\n",
    "    Multi-stream layer: Conv - ReLU - Conv - ReLU - BN\n",
    "\n",
    "    :param res_x:\n",
    "    :param res_y:\n",
    "    :param num_cams:\n",
    "    :param filter_num:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not hasattr(layer1_multistream, \"instance\"):\n",
    "        layer1_multistream.instance = 0\n",
    "    j = layer1_multistream.instance\n",
    "    seq = Sequential()\n",
    "    seq.add(Conv2D(filter_num, (3, 3), input_shape=(res_x, res_y, num_cams),\n",
    "                   padding='valid', name=f'S1_C10_{j}', activation='relu'))\n",
    "    seq.add(Conv2D(filter_num, (3, 3), input_shape=(res_x-2, res_y-2, 70),\n",
    "                   padding='valid', name=f'S1_C20_{j}'))\n",
    "    seq.add(BatchNormalization(axis=-1, name=f'S1_BN0_{j}'))\n",
    "    seq.add(Activation('relu'))\n",
    "\n",
    "    seq.add(Conv2D(filter_num, (3, 3), input_shape=(res_x-4, res_y-4, 70),\n",
    "                   padding='valid', name=f'S1_C11_{j}', activation='relu'))\n",
    "    seq.add(Conv2D(filter_num, (3, 3), input_shape=(res_x-6, res_y-6, 70),\n",
    "                   padding='valid', name=f'S1_C21_{j}'))\n",
    "    seq.add(BatchNormalization(axis=-1, name=f'S1_BN1_{j}'))\n",
    "    seq.add(Activation('relu'))\n",
    "\n",
    "    seq.add(Conv2D(filter_num, (3, 3), input_shape=(res_x-8, res_y-8, 70),\n",
    "                   padding='valid', name=f'S1_C12_{j}', activation='relu'))\n",
    "    seq.add(Conv2D(filter_num, (3, 3), input_shape=(res_x-10, res_y-10, 70),\n",
    "                   padding='valid', name=f'S1_C22_{j}'))\n",
    "    seq.add(BatchNormalization(axis=-1, name=f'S1_BN2_{j}'))\n",
    "    seq.add(Activation('relu'))\n",
    "    layer1_multistream.instance += 1\n",
    "    return seq\n",
    "\n",
    "\n",
    "def efficientnet():\n",
    "    \"\"\"\n",
    "    Merged layer: Conv - ReLU - Conv - ReLU - BN\n",
    "\n",
    "    :return: seq:\n",
    "    \"\"\"\n",
    "    block_config = efficientnet_model.BlockConfig()\n",
    "    blocks =  (# (input_filters, output_filters, kernel_size, num_repeat,\n",
    "              #  expand_ratio, strides, se_ratio)\n",
    "              # pylint: disable=bad-whitespace\n",
    "              block_config.from_args(32, 16, 3, 1, 1, (1, 1), 0.25),\n",
    "              block_config.from_args(16, 24, 3, 2, 6, (2, 2), 0.25),\n",
    "              block_config.from_args(24, 40, 5, 2, 6, (2, 2), 0.25),\n",
    "              block_config.from_args(40, 80, 3, 3, 6, (2, 2), 0.25),\n",
    "              block_config.from_args(80, 112, 5, 3, 6, (1, 1), 0.25),\n",
    "              block_config.from_args(112, 192, 5, 4, 6, (2, 2), 0.25),\n",
    "              block_config.from_args(192, 320, 3, 1, 6, (1, 1), 0.25),\n",
    "             )\n",
    "      \n",
    "    seq = efficientnet_model.EfficientNet(overrides={'num_classes': 3, 'input_channels': 140,\n",
    "                                                     'rescale_input': False, 'blocks':blocks,\n",
    "                                                     'width_coefficient':2.0})\n",
    "    return seq\n",
    "\n",
    "\n",
    "def define_epidef(sz_input1, sz_input2, view_n, filter_num):\n",
    "    \"\"\"\n",
    "    Compiles the full network.\n",
    "\n",
    "    :param sz_input1: resX\n",
    "    :param sz_input2: resY\n",
    "    :param view_n: num_cams\n",
    "    :param filter_num: number of channels in multistream layers\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 2-Input: Conv - ReLU - Conv - ReLU - BN\n",
    "    input_stack_vert = Input(shape=(sz_input1, sz_input2, view_n), name='input_stack_vert')\n",
    "    input_stack_hori = Input(shape=(sz_input1, sz_input2, view_n), name='input_stack_hori')\n",
    "\n",
    "    # 2-Stream layer: Conv - ReLU - Conv - ReLU - BN\n",
    "    mid_vert = layer1_multistream(sz_input1, sz_input2, view_n, filter_num)(input_stack_vert)\n",
    "    mid_hori = layer1_multistream(sz_input1, sz_input2, view_n, filter_num)(input_stack_hori)\n",
    "\n",
    "    # Merge layers\n",
    "    mid_merged = concatenate([mid_vert, mid_hori])\n",
    "    mid_merged_ = efficientnet()\n",
    "\n",
    "    output = mid_merged_(mid_merged)\n",
    "    model_512 = Model(inputs=[input_stack_vert, input_stack_hori], outputs=[output])\n",
    "    metrics = ['accuracy',\n",
    "               tf.keras.metrics.Precision(name='precision'),\n",
    "               tf.keras.metrics.Recall(name='recall')]\n",
    "    model_512.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)\n",
    "    model_512.summary()\n",
    "    return model_512\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_stack_vert (InputLayer)   [(None, 236, 236, 7) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_stack_hori (InputLayer)   [(None, 236, 236, 7) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 224, 224, 70) 226170      input_stack_vert[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 224, 224, 70) 226170      input_stack_hori[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_4 (TensorFlo [(None, 224, 224, 14 0           sequential_8[0][0]               \n",
      "                                                                 sequential_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet (EfficientNet)     (None, 3)            15732347    tf_op_layer_concat_4[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 16,184,687\n",
      "Trainable params: 16,099,815\n",
      "Non-trainable params: 84,872\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_epidef(236, 236, 7, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lightfield paths...\n",
      "Good: 0.551051051051051\n",
      "Scratch: 0.22447447447447447\n",
      "Dent: 0.22447447447447447\n",
      "Error: 0.0\n",
      "Done loading lightfield paths.\n",
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_stack_vert (InputLayer)   [(None, 236, 236, 7) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_stack_hori (InputLayer)   [(None, 236, 236, 7) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 224, 224, 70) 226170      input_stack_vert[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 224, 224, 70) 226170      input_stack_hori[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat_6 (TensorFlo [(None, 224, 224, 14 0           sequential_12[0][0]              \n",
      "                                                                 sequential_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "efficientnet (EfficientNet)     (None, 3)            15732347    tf_op_layer_concat_6[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 16,184,687\n",
      "Trainable params: 16,099,815\n",
      "Non-trainable params: 84,872\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      "70/70 - 20s - loss: 2.6490 - accuracy: 0.4143 - precision: 0.4118 - recall: 0.4000 - val_loss: 7.3178 - val_accuracy: 0.2000 - val_precision: 0.2000 - val_recall: 0.2000\n",
      "Epoch 2/200\n",
      "70/70 - 19s - loss: 2.5611 - accuracy: 0.3857 - precision: 0.3768 - recall: 0.3714 - val_loss: 14.8269 - val_accuracy: 0.5333 - val_precision: 0.5333 - val_recall: 0.5333\n",
      "Epoch 3/200\n",
      "70/70 - 19s - loss: 2.5890 - accuracy: 0.4143 - precision: 0.4265 - recall: 0.4143 - val_loss: 86.8464 - val_accuracy: 0.2667 - val_precision: 0.2667 - val_recall: 0.2667\n",
      "Epoch 4/200\n",
      "70/70 - 19s - loss: 2.3418 - accuracy: 0.4429 - precision: 0.4308 - recall: 0.4000 - val_loss: 7869.5205 - val_accuracy: 0.3000 - val_precision: 0.3000 - val_recall: 0.3000\n",
      "Epoch 5/200\n",
      "70/70 - 20s - loss: 2.2287 - accuracy: 0.5429 - precision: 0.5362 - recall: 0.5286 - val_loss: 3873.0676 - val_accuracy: 0.3667 - val_precision: 0.3667 - val_recall: 0.3667\n",
      "Epoch 6/200\n",
      "70/70 - 19s - loss: 2.2819 - accuracy: 0.4286 - precision: 0.4348 - recall: 0.4286 - val_loss: 1895.0255 - val_accuracy: 0.5667 - val_precision: 0.5667 - val_recall: 0.5667\n",
      "Epoch 7/200\n",
      "70/70 - 19s - loss: 2.1951 - accuracy: 0.4571 - precision: 0.4545 - recall: 0.4286 - val_loss: 5321.2505 - val_accuracy: 0.3333 - val_precision: 0.3448 - val_recall: 0.3333\n",
      "Epoch 8/200\n",
      "70/70 - 19s - loss: 2.1981 - accuracy: 0.3714 - precision: 0.3906 - recall: 0.3571 - val_loss: 40.4502 - val_accuracy: 0.4000 - val_precision: 0.4000 - val_recall: 0.4000\n",
      "Epoch 9/200\n",
      "70/70 - 20s - loss: 1.9080 - accuracy: 0.4143 - precision: 0.4091 - recall: 0.3857 - val_loss: 881.1437 - val_accuracy: 0.4000 - val_precision: 0.4000 - val_recall: 0.4000\n",
      "Epoch 10/200\n",
      "70/70 - 20s - loss: 1.9178 - accuracy: 0.4429 - precision: 0.4762 - recall: 0.4286 - val_loss: 99.3736 - val_accuracy: 0.1667 - val_precision: 0.1667 - val_recall: 0.1667\n",
      "Epoch 11/200\n",
      "70/70 - 20s - loss: 1.9029 - accuracy: 0.4000 - precision: 0.3793 - recall: 0.3143 - val_loss: 89.5110 - val_accuracy: 0.1667 - val_precision: 0.1667 - val_recall: 0.1667\n",
      "Epoch 12/200\n",
      "70/70 - 20s - loss: 1.6135 - accuracy: 0.4714 - precision: 0.5490 - recall: 0.4000 - val_loss: 15.1564 - val_accuracy: 0.4333 - val_precision: 0.4333 - val_recall: 0.4333\n",
      "Epoch 13/200\n",
      "70/70 - 20s - loss: 1.8949 - accuracy: 0.4286 - precision: 0.4219 - recall: 0.3857 - val_loss: 5.1172 - val_accuracy: 0.1667 - val_precision: 0.1667 - val_recall: 0.1667\n",
      "Epoch 14/200\n",
      "70/70 - 19s - loss: 1.5550 - accuracy: 0.4429 - precision: 0.4727 - recall: 0.3714 - val_loss: 36.8963 - val_accuracy: 0.2000 - val_precision: 0.2000 - val_recall: 0.2000\n",
      "Epoch 15/200\n",
      "70/70 - 20s - loss: 1.4855 - accuracy: 0.5143 - precision: 0.5345 - recall: 0.4429 - val_loss: 36.1292 - val_accuracy: 0.2000 - val_precision: 0.2143 - val_recall: 0.2000\n",
      "Epoch 16/200\n",
      "70/70 - 20s - loss: 1.8728 - accuracy: 0.3857 - precision: 0.3833 - recall: 0.3286 - val_loss: 52.8101 - val_accuracy: 0.2000 - val_precision: 0.2000 - val_recall: 0.2000\n",
      "Epoch 17/200\n",
      "70/70 - 22s - loss: 1.6782 - accuracy: 0.4000 - precision: 0.3800 - recall: 0.2714 - val_loss: 177.1913 - val_accuracy: 0.5333 - val_precision: 0.5333 - val_recall: 0.5333\n",
      "Epoch 18/200\n",
      "70/70 - 20s - loss: 1.7066 - accuracy: 0.5143 - precision: 0.5156 - recall: 0.4714 - val_loss: 20.2022 - val_accuracy: 0.2000 - val_precision: 0.2000 - val_recall: 0.2000\n",
      "Epoch 19/200\n",
      "70/70 - 20s - loss: 1.7722 - accuracy: 0.4000 - precision: 0.3404 - recall: 0.2286 - val_loss: 84.3227 - val_accuracy: 0.5333 - val_precision: 0.5333 - val_recall: 0.5333\n",
      "Epoch 20/200\n",
      "70/70 - 20s - loss: 1.7069 - accuracy: 0.5143 - precision: 0.5000 - recall: 0.4143 - val_loss: 503.0621 - val_accuracy: 0.5333 - val_precision: 0.5333 - val_recall: 0.5333\n",
      "Epoch 21/200\n",
      "70/70 - 19s - loss: 1.5999 - accuracy: 0.4143 - precision: 0.4286 - recall: 0.3857 - val_loss: 62.0997 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000\n",
      "Epoch 22/200\n",
      "70/70 - 20s - loss: 1.6519 - accuracy: 0.4857 - precision: 0.5246 - recall: 0.4571 - val_loss: 678.4169 - val_accuracy: 0.2000 - val_precision: 0.2000 - val_recall: 0.2000\n",
      "Epoch 23/200\n",
      "70/70 - 21s - loss: 1.7109 - accuracy: 0.4286 - precision: 0.4000 - recall: 0.3143 - val_loss: 140.8109 - val_accuracy: 0.2000 - val_precision: 0.2000 - val_recall: 0.2000\n",
      "Epoch 24/200\n",
      "70/70 - 21s - loss: 1.5280 - accuracy: 0.5000 - precision: 0.4912 - recall: 0.4000 - val_loss: 141.4135 - val_accuracy: 0.2667 - val_precision: 0.2143 - val_recall: 0.2000\n",
      "Epoch 25/200\n",
      "70/70 - 21s - loss: 1.6002 - accuracy: 0.4429 - precision: 0.4600 - recall: 0.3286 - val_loss: 15.0994 - val_accuracy: 0.1333 - val_precision: 0.1379 - val_recall: 0.1333\n",
      "Epoch 26/200\n",
      "70/70 - 21s - loss: 1.6460 - accuracy: 0.4429 - precision: 0.4677 - recall: 0.4143 - val_loss: 27.6626 - val_accuracy: 0.2333 - val_precision: 0.2333 - val_recall: 0.2333\n",
      "Epoch 27/200\n",
      "70/70 - 21s - loss: 1.6311 - accuracy: 0.4429 - precision: 0.4286 - recall: 0.3000 - val_loss: 5.6592 - val_accuracy: 0.1333 - val_precision: 0.1333 - val_recall: 0.1333\n",
      "Epoch 28/200\n",
      "70/70 - 20s - loss: 1.5343 - accuracy: 0.5000 - precision: 0.5102 - recall: 0.3571 - val_loss: 12.4593 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000\n",
      "Epoch 29/200\n",
      "70/70 - 20s - loss: 1.5659 - accuracy: 0.5000 - precision: 0.4746 - recall: 0.4000 - val_loss: 5.8283 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.3333\n",
      "Epoch 30/200\n",
      "70/70 - 21s - loss: 1.4583 - accuracy: 0.4429 - precision: 0.4717 - recall: 0.3571 - val_loss: 3.3405 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.3333\n",
      "Epoch 31/200\n",
      "70/70 - 22s - loss: 1.6120 - accuracy: 0.4000 - precision: 0.4000 - recall: 0.3143 - val_loss: 1.5741 - val_accuracy: 0.3000 - val_precision: 0.2857 - val_recall: 0.2667\n",
      "Epoch 32/200\n",
      "70/70 - 21s - loss: 1.6416 - accuracy: 0.4714 - precision: 0.4630 - recall: 0.3571 - val_loss: 1.3604 - val_accuracy: 0.5333 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/200\n",
      "70/70 - 22s - loss: 1.6102 - accuracy: 0.4571 - precision: 0.4262 - recall: 0.3714 - val_loss: 10.5721 - val_accuracy: 0.3333 - val_precision: 0.3333 - val_recall: 0.2667\n",
      "Epoch 34/200\n",
      "70/70 - 20s - loss: 1.5051 - accuracy: 0.4571 - precision: 0.5172 - recall: 0.4286 - val_loss: 4.7062 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000\n",
      "Epoch 35/200\n",
      "70/70 - 21s - loss: 1.5279 - accuracy: 0.4000 - precision: 0.4630 - recall: 0.3571 - val_loss: 1.8696 - val_accuracy: 0.2333 - val_precision: 0.2105 - val_recall: 0.1333\n",
      "Epoch 36/200\n",
      "70/70 - 20s - loss: 1.5572 - accuracy: 0.4571 - precision: 0.4746 - recall: 0.4000 - val_loss: 10.7622 - val_accuracy: 0.4000 - val_precision: 0.4000 - val_recall: 0.3333\n",
      "Epoch 37/200\n",
      "70/70 - 20s - loss: 1.4361 - accuracy: 0.4571 - precision: 0.4912 - recall: 0.4000 - val_loss: 4.4547 - val_accuracy: 0.1667 - val_precision: 0.1724 - val_recall: 0.1667\n",
      "Epoch 38/200\n",
      "70/70 - 21s - loss: 1.6393 - accuracy: 0.4571 - precision: 0.4655 - recall: 0.3857 - val_loss: 2.4979 - val_accuracy: 0.4667 - val_precision: 0.4828 - val_recall: 0.4667\n",
      "Epoch 39/200\n",
      "70/70 - 23s - loss: 1.5088 - accuracy: 0.4429 - precision: 0.4262 - recall: 0.3714 - val_loss: 1.3566 - val_accuracy: 0.5333 - val_precision: 0.5333 - val_recall: 0.5333\n",
      "Epoch 40/200\n",
      "70/70 - 27s - loss: 1.4792 - accuracy: 0.4714 - precision: 0.4918 - recall: 0.4286 - val_loss: 1.6610 - val_accuracy: 0.5000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/200\n",
      "70/70 - 22s - loss: 1.6247 - accuracy: 0.4143 - precision: 0.4516 - recall: 0.4000 - val_loss: 6.6629 - val_accuracy: 0.2333 - val_precision: 0.2400 - val_recall: 0.2000\n",
      "Epoch 42/200\n",
      "70/70 - 22s - loss: 1.6550 - accuracy: 0.4286 - precision: 0.4386 - recall: 0.3571 - val_loss: 2.3792 - val_accuracy: 0.5333 - val_precision: 0.5333 - val_recall: 0.5333\n",
      "Epoch 43/200\n",
      "70/70 - 21s - loss: 1.5278 - accuracy: 0.4286 - precision: 0.5000 - recall: 0.4000 - val_loss: 1.4589 - val_accuracy: 0.5333 - val_precision: 0.5333 - val_recall: 0.5333\n",
      "Epoch 44/200\n",
      "70/70 - 21s - loss: 1.5348 - accuracy: 0.4143 - precision: 0.4821 - recall: 0.3857 - val_loss: 14.1756 - val_accuracy: 0.4333 - val_precision: 0.4138 - val_recall: 0.4000\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-87edbc29f6f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m# exponential_decay_fn = exponential_decay(0.01, 20)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;31m# lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m model.fit(generator_train, epochs=200, max_queue_size=10, initial_epoch=iter00, verbose=2,\n\u001b[0m\u001b[0;32m     65\u001b[0m           validation_data=generator_test)\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from epidef_fun.util import get_list_IDs\n",
    "from epidef_fun.DataGenerator import DataGenerator\n",
    "\n",
    "\n",
    "network_name = 'EPIDef_train'\n",
    "iter00 = 0\n",
    "load_weights = False\n",
    "\"\"\"\n",
    "Model parameters:\n",
    "    first layer:  3 convolutional blocks\n",
    "    second layer: 6 convolutional blocks\n",
    "    last layer:   1 dense block?\n",
    "\"\"\"\n",
    "model_filter_number = 70\n",
    "model_learning_rate = 1e-5\n",
    "batch_size = 1\n",
    "input_res = 236\n",
    "\n",
    "# Define directory for saving checkpoint files:\n",
    "directory_ckp = f\"epidef_checkpoints\\\\{network_name}_ckp\"\n",
    "if not os.path.exists(directory_ckp):\n",
    "    os.makedirs(directory_ckp)\n",
    "if not os.path.exists('epidef_output\\\\'):\n",
    "    os.makedirs('epidef_output\\\\')\n",
    "directory_t = f\"epidef_output\\\\{network_name}\"\n",
    "if not os.path.exists(directory_t):\n",
    "    os.makedirs(directory_t)\n",
    "# txt_name = f\"epidef_checkpoints\\\\lf_{network_name}.txt\"\n",
    "\n",
    "# Load training data from lightfield .png files:\n",
    "print(\"Loading lightfield paths...\")\n",
    "# dir_lf_images = (\"C:\\\\Users\\\\muell\\\\Google Drive\\\\University\\\\Master_Project\"\n",
    "#                  + \"\\\\data_storage\\\\lightfields\")\n",
    "dir_lf_images = (\"C:\\\\Users\\\\muell\\\\Desktop\\\\blender_output_tmp\")\n",
    "list_IDs = get_list_IDs(dir_lf_images)[:100]\n",
    "\n",
    "print(\"Done loading lightfield paths.\")\n",
    "fraction = np.int(len(list_IDs)*0.7)\n",
    "list_IDs_train, list_IDs_test = list_IDs[:fraction], list_IDs[fraction:]\n",
    "\n",
    "model = define_epidef(input_res, input_res, 7, model_filter_number)\n",
    "\n",
    "\n",
    "\n",
    "generator_train = DataGenerator(list_IDs_train, batch_size=batch_size, train=False)\n",
    "generator_test = DataGenerator(list_IDs_test, batch_size=batch_size, train=False)\n",
    "\n",
    "# checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"epidef_model.h5\", save_best_only=True)\n",
    "# early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "#     callbacks = [checkpoint_cb]  # , keras.callbacks.TensorBoard(log_dir='./logs')]\n",
    "# Try this out at some point:\n",
    "# def exponential_decay(lr0, s):\n",
    "#     def exponential_decay_fn(epoch):\n",
    "#         return lr0 * 0.1**(epoch/s)\n",
    "#     return exponential_decay_fn\n",
    "# exponential_decay_fn = exponential_decay(0.01, 20)\n",
    "# lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "model.fit(generator_train, epochs=200, max_queue_size=10, initial_epoch=iter00, verbose=2,\n",
    "          validation_data=generator_test)\n",
    "\n",
    "\n",
    "print(\"Weights saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
